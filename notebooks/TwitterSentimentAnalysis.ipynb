{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AWf9uXCbj8ng"
      },
      "source": [
        "## Twitter Sentiment Analysis\n",
        "### ELEC-ENG 375-475: Final Project\n",
        "Yemi Kelani\n",
        "\n",
        "\n",
        "This data was sourced from [Kaggle](https://www.kaggle.com/datasets/kazanova/sentiment140)\n",
        "\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbd7ymGcxPe9"
      },
      "source": [
        "##### **Background and Motivation**\n",
        "Sentimental analysis is done in many day-to-day interactions and is an important aspect in\n",
        "how humans communicate with each other. Certain combinations of phrases and words\n",
        "lead us to form assumptions about the otherâ€™s emotional state and dictate the way that we\n",
        "choose to respond. Sentimental analysis done by artificial intelligence has become\n",
        "necessary in recent years due to virtual assistants such as Siri or Alexa, where it becomes\n",
        "necessary to analyze not only the commands given, but the contents of the command as\n",
        "well. This is largely an area that is still being developed and is becoming more important as\n",
        "AI continues to become a facet of human life.\n",
        "\n",
        "\\\\\n",
        "\n",
        "##### **Project Goals and Objectives**\n",
        "We aim to create a model that classifies the sentiment of varying tweets as negative,\n",
        "neutral, or positive based on its associated text. The degree of sentiment will be assigned\n",
        "to a number scale. Our data is sourced from Kaggle, and contains over 1.6 million features.\n",
        "Each feature contains the target label (-1 = negative, 1 = positive ), the tweet\n",
        "text, and other information such as the tweet timestamp and id.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1pp3HoHIi-jr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# models\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.experimental import enable_halving_search_cv \n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "# from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fl76lUu9g5fP"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "j__qLdB4ZxjB"
      },
      "source": [
        "---\n",
        "#### **Data Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LtRweMGij5fq",
        "outputId": "f327bffd-ed2c-481e-d3e3-8aa029dc5a90"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-61f582e5-b438-4160-a8f2-caa601ce2b60\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61f582e5-b438-4160-a8f2-caa601ce2b60')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61f582e5-b438-4160-a8f2-caa601ce2b60 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61f582e5-b438-4160-a8f2-caa601ce2b60');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   target         ids                          date      flag  \\\n",
              "0      -1  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
              "1      -1  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
              "2      -1  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
              "3      -1  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "4      -1  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "\n",
              "              user                                               text  \n",
              "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
              "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
              "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
              "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
              "4           Karoli  @nationwideclass no, it's not behaving at all....  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "column_names = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/EE 375 475 ML Project/trainingTwitter.csv\", \n",
        "                    encoding=\"ISO-8859-1\", names=column_names)\n",
        "\n",
        "# reassign labels from [0,4] to [-1,1]\n",
        "data[\"target\"] = np.where(data[\"target\"]==0, -1, 1) \n",
        "data.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "l8jOKVkvd70L"
      },
      "source": [
        "---\n",
        "#### **A Simple Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "t5gA134tj5xW"
      },
      "outputs": [],
      "source": [
        "# create corpus\n",
        "corpus = data[\"text\"]\n",
        "tfidf_vec = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# encode via TFIDF\n",
        "X = tfidf_vec.fit_transform(corpus)\n",
        "y = data[\"target\"]\n",
        "\n",
        "# spilt data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DjxrVabqn4lo",
        "outputId": "e74c6996-5d91-47ce-d5b1-995140103be8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(solver='saga')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Logistic Regression\n",
        "logistic_model = LogisticRegression(solver='saga')\n",
        "logistic_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "b6NWZQz-oTPy",
        "outputId": "88141989-5d98-4a5d-f784-767e879b7967"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logisitic Regression CV Results: \n",
            " average fit time: 30.296721537907917 average test score: 0.7856441608766036\n"
          ]
        }
      ],
      "source": [
        "# Cross Validation\n",
        "cv = cross_validate(logistic_model, X_train, y_train, scoring=\"f1\", cv=3)\n",
        "score = cv['test_score'].mean()\n",
        "print(\"Logisitic Regression CV Results: \\n\", \n",
        "      \"average fit time:\", cv['fit_time'].mean(), \n",
        "      \"average test score:\", score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DfRo0i4XoiHu",
        "outputId": "b94fec84-0efe-4b58-8228-cb66c245bd71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model accuracy: 0.783159375\n"
          ]
        }
      ],
      "source": [
        "# Quality Metrics\n",
        "accuracy = logistic_model.score(X_test, y_test)\n",
        "print(f\"Model accuracy: {accuracy}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "G5YfKGrpPZqb"
      },
      "source": [
        "---\n",
        "#### **Hyperparameter Tuning**\n",
        "In order to improve the accuracy of our model, we can perform hyperparameter tuning via sklearn's GridSearchCV function. GridSearchCV performs a cross-validation on a series of hyperparameter combinations and keeps record of an optimal configuration. Below we opt to use the 'f1' scoring metric as opposed to 'accuracy'. The 'f1' score is the harmonic mean between precision and recall, and ultimatley results in a superior measurment of incorrectly classified samples than accuracy.\n",
        "\n",
        "Reference: [GridSearchCV guide](https://towardsdatascience.com/tuning-the-hyperparameters-of-your-machine-learning-model-using-gridsearchcv-7fc2bb76ff27)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jpa_EdcnPekg",
        "outputId": "3a6064f5-7c5a-44d3-fa25-ab06a5fa5c3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy : 0.7249534214984608\n",
            "best params : {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga'}\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "parameters = {\n",
        "  'max_iter': [1000],\n",
        "  'penalty' : ['l1','l2'], \n",
        "  'C'       : [0.1, 1, 10, 100],\n",
        "  'solver'  : ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "clf = HalvingGridSearchCV(model, param_grid=parameters, scoring='f1', cv=3)\n",
        "clf.fit(X_train[:10000], y_train[:10000])\n",
        "print(\"accuracy :\", clf.best_score_)\n",
        "print(\"best params :\", clf.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAQvtzInuh5n",
        "outputId": "77154e07-716c-4a33-a3b0-8c453e6c7f9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model accuracy: 0.7345212537569772\n"
          ]
        }
      ],
      "source": [
        "# Quality Metrics\n",
        "accuracy = clf.score(X_test, y_test)\n",
        "print(f\"Model accuracy: {accuracy}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sNilf1EKfQlv"
      },
      "source": [
        "---\n",
        "#### **Batching**\n",
        "To perform batching with sklearn's LogisticRegression class, we set the `warm start` paramerter to true. According to the documentation, `warm start` allows us to fit the model to data based on the residual from a previous training session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4gTKCLqX8IH",
        "outputId": "83069566-a635-40cd-c565-f5884d3e03ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model accuracy: 0.7653125\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression\n",
        "batch_model = LogisticRegression(solver='saga', warm_start=True)\n",
        "\n",
        "# create mini-batches\n",
        "batches = []\n",
        "num_batches = 10\n",
        "batch_size = y_train.size // num_batches\n",
        "for batch_number in range(num_batches):\n",
        "  start = batch_number * batch_size\n",
        "  end =  (batch_number+1) * batch_size\n",
        "  batches.append((X_train[start:end], y_train[start:end]))\n",
        "\n",
        "# train\n",
        "for mini_x, mini_y in batches:\n",
        "  batch_model.fit(mini_x, mini_y)\n",
        "\n",
        "# Quality Metrics\n",
        "accuracy = batch_model.score(X_test, y_test)\n",
        "print(f\"Model accuracy: {accuracy}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qBUZ7Mx4rkbA"
      },
      "source": [
        "---\n",
        "##### **Obstacles**\n",
        "Training our models on such a large dataset proved to be fairly difficult and time consuming. Trial and error quickly became an expensive method of testing parameters as seen with GridSearchCV when hyperparameter tuning. Some parameter configurations took hours to run and never converged, leaving us back at square one. To combat this issue, reduced the quantity of features we trained on when hyperparameter tuning, although it ultimately diminished the overall accuracy of our model.\n",
        "\n",
        "\\\\\n",
        "\n",
        "##### **Conclusion**\n",
        "Using a naive logistic regression approach, we were able to achieve a reasonably high accuracy of 78.3%. We attempted to improve the accuracy via hyperparameter tuning, which yielded an accuracy score of 73.4% (likely because of the obstacles mentioned above). Additionally, we attempted to run a batching algorithm as well, where we got an accuracy of 76.5%. \n",
        "\n",
        "One lingering question we have is how our model might perform on a completely separate dataset. We split our data into training and test sets to perform cross validation, so we do believe this model should be relatively robust to overfitting. However it would still be valuable to verify this on a totally new set of tweets, as all of the tweets we looked at are from 2009. Since then, Twitter has increased maximum tweet length, increased moderation standards, and has had significant shifts in its user base. \n",
        "\n",
        "Overall, this project has shown that even with basic machine learning regression models, we can train computers to access rather accurately human sentiment in human text. This suggests that with enough data and training time, as well as improvements on learning algorithms, the idea of creating artificial intelligence capable of interpreting and learning human emotions is quite a possible endeavor.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRummswz21dz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
